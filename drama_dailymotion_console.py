# -*- coding: utf-8 -*-
# The MIT License (MIT)
# Copyright (c) 2020 limkokhole@gmail.com
# 
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
# 
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
# 
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
# DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
# OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE
# OR OTHER DEALINGS IN THE SOFTWARE.

__author__ = 'Lim Kok Hole'
__copyright__ = 'Copyright 2020'
__credits__ = ['Stack Overflow Links']
__license__ = 'MIT'
__version__ = 1.0
__maintainer__ = 'Lim Kok Hole'
__email__ = 'limkokhole@gmail.com'
__status__ = 'Production'

import sys, os, traceback

PY3 = sys.version_info[0] >= 3
if not PY3:
    print('Sorry, but python 2 already RIP. Abort.')
    sys.exit()

import re
from threading import Thread
import base64
import youtube_dl

import requests
from bs4 import BeautifulSoup

# Jan 2020, Google will unify UA in future, good news :D
UA = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.100 Safari/537.36'
BOLD_ONLY = ['bold']

import argparse
from argparse import RawTextHelpFormatter
arg_parser = argparse.ArgumentParser(
    description='Dailymotion é€£çºŒåŠ‡ä¸‹è¼‰å™¨', formatter_class=RawTextHelpFormatter)

def quit(msgs, exit=True):
    if not isinstance(msgs, list):
        msgs = [msgs]
    for msg in msgs:
        if msg == '\n': # Empty line without bg color
            print('\n')
        else:
            #cprint(msg, 'white', 'on_red', attrs=BOLD_ONLY)
            print(msg)
    if exit:
        #cprint('ä¸­æ­¢ã€‚', 'white', 'on_red', attrs=BOLD_ONLY)
        print('ä¸­æ­¢ã€‚')
        sys.exit()

arg_parser.add_argument('-any', '--any-website', dest='any_website', action='store_true', help='ä¸ä¸‹è¼‰ä¸»é¡Œ drama dailymotion è€Œæ˜¯ä¸‹è¼‰å…¶å®ƒç¶²ç«™ä¾‹å¦‚ YouTubeã€‚')
arg_parser.add_argument('-d', '--dir', help='ç›®éŒ„è·¯å¾‘ã€‚')
arg_parser.add_argument('-from-ep', '--from-ep', dest='from_ep', default=1, type=int, help='å¾ç¬¬å¹¾é›†é–‹å§‹ä¸‹è¼‰ã€‚')
arg_parser.add_argument('-to-ep', '--to-ep', dest='to_ep',
                        type=int, help='åˆ°ç¬¬å¹¾é›†åœæ­¢ä¸‹è¼‰ã€‚')
arg_parser.add_argument('url', nargs='?', help='é€£çºŒåŠ‡ç¶²å€ã€‚')
args, remaining = arg_parser.parse_known_args()

def main(arg_dir, arg_from_ep, arg_to_ep, arg_url, custom_stdout, arg_any_website):

    try:
        sys.stdout = custom_stdout

        if not arg_url:
            print('ç¶²å€åƒæ•¸: ' + repr(arg_url))
            quit('[!] [e1] è«‹è¼¸å…¥ç¶²å€åƒæ•¸, ä¾‹å­ï¼š https://dramaq.de/cn191023b/ã€‚ ä¸­æ­¢ã€‚')

        if not arg_dir:
            quit('[!] è«‹ç”¨ `-d DIR` åƒæ•¸è¼¸å…¥ç›®éŒ„è·¯å¾‘ã€‚ä¸­æ­¢ã€‚')

        dir_path_m = os.path.abspath(arg_dir)
        if not os.path.isdir(dir_path_m):
            try:
                os.makedirs(dir_path_m)
            except OSError:
                quit('[i] ç„¡æ³•å‰µå»ºç›®éŒ„ã€‚ä¸­æ­¢ã€‚')

        urls = []

        if not arg_any_website:

            try:
                if '.html' in arg_url.split('/')[-1]:
                    template_url = '/'.join(arg_url.split('/')[:-1]) + '/'
                elif not arg_url.endswith('/'):
                    template_url = arg_url + '/'
                else:
                    template_url = arg_url

                if not template_url.startswith('http'):
                    # http supposed to auto-redirect to https
                    template_url = 'http://' + template_url

            except Exception as e:
                quit('[!] [e1] è«‹è¼¸å…¥ç¶²å€åƒæ•¸, ä¾‹å­ï¼š https://dramaq.de/cn191023b/ã€‚ ä¸­æ­¢ã€‚')

            if not arg_to_ep:
                quit('[!] è«‹ç”¨ `--to-ep N` åƒæ•¸è¼¸å…¥ä¸‹è¼‰åˆ°ç¬¬å¹¾é›†åœæ­¢ã€‚ ä¸­æ­¢ã€‚')
            arg_to_ep+=1

            http_headers = {
                'User-Agent': UA
            }
            
            for ep in range(arg_from_ep, arg_to_ep):
                url = ''.join([template_url, str(ep), '.html']) 

                print('å˜—è©¦ URL: {}'.format(url) )
                r = requests.get(url, allow_redirects=True, headers=http_headers, timeout=30)
                # Use .content instead of .text(), https://stackoverflow.com/q/36833357/1074998
                soup = BeautifulSoup(r.content, 'html.parser')
                #cols = soup.findAll( 'a', text = re.compile("/*Dailymotion$")} )
                cols = soup.findAll( 'a' )
                # E.g. <a href="#4" data-data="91lI4dDOwZnSml2UJFjM1ZHcRxmdrJyW6IycklmIsIibvlGdv1WeslWYEJiOiU2YyV3bzJye"><strong>ç‰‡æºäº”</strong><small>Dailymotion</small></a>
                
                try:
                    for c in cols:
                        if 'dailymotion' in c.text.lower():
                            print(c.text) #ç‰‡æºäº”Dailymotion
                            print('base64 (ä¹‹å‰): ' + c.get('data-data')) #91lIFFUMnZXen5WM1NlT0kldrl3NrJyW6IycklmIsIibvlGdv1WeslWYEJiOiU2YyV3bzJye
                            # Reverse first then decode with base64
                            decoded_dailymotion = str(base64.b64decode( c.get('data-data')[::-1] ) )
                            print('base64 (ä¹‹å¾Œ): ' + repr(decoded_dailymotion)) #b'{"source":"Dailymotion","ids":["k7ykvY4NSu1ngyvg1AE"]}'
                            vid = decoded_dailymotion.split('"ids":["')[1].split('"')[0]
                            url = 'https://www.dailymotion.com/embed/video/' + str(vid)
                            print('vid: ' + repr(url))
                            if not url:
                                raise Exception('Come on, I know Python: No url vid.')
                            urls.append(url)
                    if not urls:
                        raise Exception('Come on, I really know Python: No url vids.')
                except Exception as e:
                    print(traceback.format_exc())
                    quit('è§£æå¤±è´¥ã€‚è¯·å» https://github.com/limkokhole/drama-dailymotion-downloader å¼€ issueã€‚')

        else:
            urls.append(arg_url)

        print('ç½‘å€: ' + repr(urls))

        #ep_url = 'https://www.dailymotion.com/embed/video/k63bEEZe7ORnoRvoNaz'

        threads = []
        def download( ep_url ):
            try: # This one shouldn't pass .mp4 ep_path
                youtube_dl.YoutubeDL(params={'-c': '', '-q': '', '--no-mtime': '',
                    'outtmpl': dir_path_m + '/%(title)s-%(upload_date)s-%(id)s.%(ext)s'}).download([ep_url])
            except youtube_dl.utils.DownloadError:
                print(traceback.format_exc())
                sys.exit()
                
        #for url in ['https://www.dailymotion.com/embed/video/k63bEEZe7ORnoRvoNaz', ]
        for url in urls:
            t = Thread( target=download, args=(url,) )
            t.start()
            threads.append(t)

        for t in threads:
            t.join()
        

    except Exception:
        # Need to catch & print exception explicitly to pass to duboku_gui to show err log
        print(traceback.format_exc())

    print('[ğŸ˜„] å…¨éƒ¨ä¸‹è¼‰å·¥ä½œå®Œç•¢ã€‚æ‚¨å·²å¯ä»¥é—œé–‰çª—å£, æˆ–ä¸‹è¼‰åˆ¥çš„è¦–é »ã€‚')

if __name__ == "__main__":
    main(args.dir, args.from_ep, args.to_ep, args.url, sys.stdout, args.any_website)

